version: '3'

services:

  # Front end
  streamlit-app:
    build:
      context: ./streamlit_app
      dockerfile: Dockerfile
    command:
      [
        "streamlit",
        "run",
        "dashboard.py",
        "--server.port=8501"
      ]
    # ports:
    #   - "8501:8501"
    networks:
      llama3-network:
        ipv4_address: 172.20.0.3
    restart: always
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Back end llm api
  llama3:
    image: langchain4j/ollama-llama3
    networks:
      - llama3-network
    container_name: llama3
    restart: always

  apache:
    build:
      context: .
      dockerfile: Dockerfile-apache
    ports:
      - "8457:80"
    volumes:
      - ./apache-config:/usr/local/apache2/conf/extra/
    container_name: apache_webserver
    restart: always
    depends_on:
      - streamlit-app
    networks:
      - llama3-network

# Networks
networks:
  llama3-network:
    name: llama3-network
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
