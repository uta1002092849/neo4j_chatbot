version: '3.8'

services:
  streamlit-app:
    build:
      context: ./streamlit_app
      dockerfile: dockerfile
    ports:
      - "8501:8501"
    depends_on:
      - llama3
    command:
      [
        "streamlit",
        "run",
        "dashboard.py",
        "--server.port=8501"
      ]
    networks:
      - llama3-network

  llama3:
    image: langchain4j/ollama-llama3
    ports:
      - "11434:11434"
    networks:
      - llama3-network
    container_name: llama3
    restart: always
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0

networks:
  llama3-network:
    external: false
